{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Flatten, BatchNormalization, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = img_width = 150\n",
    "channels = 3\n",
    "if (channels == 1):\n",
    "    color_mode_ = \"grayscale\"\n",
    "else:\n",
    "    color_mode_ = \"rgb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('/data/data_fakemotion_train_text/data_new.csv')\n",
    "data2 = pd.read_csv('/data/new_data1/new_data1.csv').drop('Unnamed: 0', axis=1)\n",
    "data3 = pd.read_csv('/data/new_data2/new_data2.csv').drop('Unnamed: 0', axis=1)\n",
    "data4 = pd.read_csv('/data/new_data3/new_data3.csv').drop('Unnamed: 0', axis=1)\n",
    "data5 = pd.read_csv('/data/new_data4/new_data4.csv').drop('Unnamed: 0', axis=1)\n",
    "data6 = pd.read_csv('/data/new_data5/new_data5.csv').drop('Unnamed: 0', axis=1)\n",
    "data = pd.concat([data1,data2,data3,data4,data5,data6], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4, 6, 3, 5, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.emotion.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data[data.emotion == 6].index.values)\n",
    "data = data.drop(data[data.emotion == 2].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace({'emotion': {5: 2}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24568"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24568, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 48, 48\n",
    "\n",
    "datapoints = data['pixels'].tolist()\n",
    "\n",
    "#getting features for training\n",
    "X = []\n",
    "for xseq in datapoints:\n",
    "    xx = [int(xp) for xp in xseq.split(' ')]\n",
    "    xx = np.asarray(xx).reshape(img_width, img_height)\n",
    "    X.append(xx.astype('float32'))\n",
    "\n",
    "X = np.asarray(X)\n",
    "X = np.expand_dims(X, -1)\n",
    "\n",
    "#getting labels for training\n",
    "# y = pd.get_dummies(data['emotion']).as_matrix()\n",
    "y = data.emotion\n",
    "\n",
    "#reducing\n",
    "# X = X[:5000]\n",
    "# y = y[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = X[:22000], y[:22000]\n",
    "# X_test, y_test = X[22000:], y[22000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "Xtrain = []\n",
    "for i in range(len(X_train)):\n",
    "    Xtrain.append(cv2.cvtColor(X_train[i],cv2.COLOR_GRAY2RGB))\n",
    "X_train = np.array(Xtrain)\n",
    "\n",
    "Xtest = []\n",
    "for i in range(len(X_test)):\n",
    "    Xtest.append(cv2.cvtColor(X_test[i],cv2.COLOR_GRAY2RGB))\n",
    "X_test = np.array(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(y_train, 5)\n",
    "y_test = np_utils.to_categorical(y_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19654, 48, 48, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7e11f30a58>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0]/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19654, 5)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
      "  Cloning https://github.com/rcmalli/keras-vggface.git to /tmp/pip-req-build-wu493dk5\n",
      "  Running command git clone -q https://github.com/rcmalli/keras-vggface.git /tmp/pip-req-build-wu493dk5\n",
      "Requirement already satisfied (use --upgrade to upgrade): keras-vggface==0.6 from git+https://github.com/rcmalli/keras-vggface.git in /opt/ds3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/ds3/lib/python3.6/site-packages (from keras-vggface==0.6) (1.16.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/ds3/lib/python3.6/site-packages (from keras-vggface==0.6) (1.2.1)\n",
      "Requirement already satisfied: h5py in /opt/ds3/lib/python3.6/site-packages (from keras-vggface==0.6) (2.9.0)\n",
      "Requirement already satisfied: pillow in /opt/ds3/lib/python3.6/site-packages (from keras-vggface==0.6) (5.4.1)\n",
      "Requirement already satisfied: keras in /opt/ds3/lib/python3.6/site-packages (from keras-vggface==0.6) (2.2.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/ds3/lib/python3.6/site-packages (from keras-vggface==0.6) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in /opt/ds3/lib/python3.6/site-packages (from keras-vggface==0.6) (3.13)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/ds3/lib/python3.6/site-packages (from keras->keras-vggface==0.6) (1.0.5)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/ds3/lib/python3.6/site-packages (from keras->keras-vggface==0.6) (1.0.6)\n",
      "Building wheels for collected packages: keras-vggface\n",
      "  Building wheel for keras-vggface (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-vggface: filename=keras_vggface-0.6-cp36-none-any.whl size=8310 sha256=8bbedde4c8550bcdd744f56768ed017f0cf48e915384ebfe70ee72c7c9f494df\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_r8wvsn5/wheels/36/07/46/06c25ce8e9cd396dabe151ea1d8a2bc28dafcb11321c1f3a6d\n",
      "Successfully built keras-vggface\n",
      "\u001b[33mWARNING: You are using pip version 19.2.1, however version 19.2.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/rcmalli/keras-vggface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "<keras.engine.input_layer.InputLayer object at 0x7f7e11ed4518> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7e11f3be10> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7e11f3bdd8> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f7e11efa320> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7e11efaf60> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7e11ea9ac8> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f7e11ec93c8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7e11ec9d68> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7e09c91e80> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7e09c4f5f8> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f7e09c74400> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7e09c74da0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7e09c12eb8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7e09bd1630> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f7e09bf3438> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7e09bf3dd8> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7e09b91ef0> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7e09b4d668> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f7e09b73470> True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vggface_vgg16 (Model)        (None, 1, 1, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 15,109,957\n",
      "Trainable params: 9,834,501\n",
      "Non-trainable params: 5,275,456\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ds3/lib/python3.6/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=5)`\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_vggface.vggface import VGGFace\n",
    "\n",
    "#Load the VGG model\n",
    "vgg_conv = VGGFace(include_top=False, input_shape=(img_width,img_height,channels))\n",
    "print(len(vgg_conv.layers))\n",
    "# Freeze some layers\n",
    "\n",
    "# We freeze three layers\n",
    "for layer in vgg_conv.layers[:-6]:\n",
    "    layer.trainable = False\n",
    "    pass\n",
    "\n",
    "\n",
    "# Check the trainable status of the individual layers\n",
    "for layer in vgg_conv.layers:\n",
    "    print(layer, layer.trainable)\n",
    "\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "# Create the model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add the vgg convolutional base model\n",
    "model.add(vgg_conv)\n",
    "\n",
    "# we add a fully connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# we compute the softmax according to 5 classes because we have 5 classes\n",
    "\n",
    "predictions = model.add(Dense(output_dim = 5, activation = 'softmax'))\n",
    "\n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "from keras import optimizers\n",
    "adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "19654/19654 [==============================] - 17s 845us/step - loss: 2.0068 - acc: 0.3537\n",
      "Epoch 2/80\n",
      "19654/19654 [==============================] - 15s 783us/step - loss: 1.5086 - acc: 0.3648\n",
      "Epoch 3/80\n",
      "19654/19654 [==============================] - 15s 783us/step - loss: 1.4614 - acc: 0.3647\n",
      "Epoch 4/80\n",
      "19654/19654 [==============================] - 15s 784us/step - loss: 1.4371 - acc: 0.3648\n",
      "Epoch 5/80\n",
      "19654/19654 [==============================] - 15s 783us/step - loss: 1.4285 - acc: 0.3646\n",
      "Epoch 6/80\n",
      " 3000/19654 [===>..........................] - ETA: 13s - loss: 1.4284 - acc: 0.3653"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=100, epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# # load json and create model\n",
    "# json_file = open('model.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# loaded_model = model_from_json(loaded_model_json)\n",
    "# # load weights into new model\n",
    "# loaded_model.load_weights(\"model.h5\")\n",
    "# print(\"Loaded model from disk\")\n",
    " \n",
    "# # evaluate loaded model on test data\n",
    "# loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "# score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "# print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lbl = []\n",
    "y_test_lbl = []\n",
    "for yp, yt in zip(y_pred, y_test):\n",
    "    id_max_pred = np.argmax(yp)\n",
    "    y_pred_lbl.append(id_max_pred)\n",
    "    id_max_test = np.argmax(yt)\n",
    "    y_test_lbl.append(id_max_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_lbl[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test_lbl, y_pred_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test_lbl, y_pred_lbl)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np.array(y_pred_lbl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np.array(y_test_lbl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(y_pred[:30,1])\n",
    "plt.plot(y_pred[:30,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# # Change the batchsize according to your system RAM\n",
    "# train_batchsize = 100\n",
    "# val_batchsize = 10\n",
    "\n",
    "# # train_generator = train_datagen.flow_from_directory(\n",
    "# #     train_folder,\n",
    "# #     target_size=(img_height, img_width),\n",
    "# #     batch_size=train_batchsize,\n",
    "# #     class_mode='categorical')\n",
    "\n",
    "\n",
    "# train_generator = train_datagen.flow(X_train, y_train, batch_size=train_batchsize)\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # validation_generator = validation_datagen.flow_from_directory(\n",
    "# #     test_folder,\n",
    "# #     target_size=(img_height, img_width),\n",
    "# #     batch_size=val_batchsize,\n",
    "# #     class_mode='categorical',\n",
    "# #     shuffle=False)\n",
    "\n",
    "# validation_generator = validation_datagen.flow(X_test, y_test, batch_size=val_batchsize)\n",
    "\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit_generator(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=train_generator.n / train_generator.batch_size,\n",
    "#     epochs=20)\n",
    "# #     validation_data=validation_generator,\n",
    "# #     validation_steps=validation_generator.n / validation_generator.batch_size,\n",
    "# #     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
